{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook exercices chinois - Pix Langue\n",
    "\n",
    "Résumé de ce qu'il y a dans le note book :\n",
    "\n",
    "exo vocabulaire => FlashCard / QCM 4 distracteurs de meme pos / QCM 4 distracteurs les plus similaire / QCM 4 distracteurs de meme pos + affiche la phrase en langue target\n",
    "\n",
    "exo phrase => phrase à trous - 4 distractors de meme pos / phrase à trous - 4 distractors les plus similaire / Remettre les mots dans le bon ordre pour traduire une phrase\n",
    "\n",
    "Pandas DataFrame Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy,random,requests\n",
    "from nltk.corpus import wordnet\n",
    "nlpCh=spacy.load(\"zh_core_web_md\")\n",
    "nlpFr = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Corpus mot chinois.csv\")\n",
    "data_phonetique = pd.read_csv(\"Phonetique Chinoise.csv\")\n",
    "data_phrase = pd.read_csv(\"Phrase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French</th>\n",
       "      <th>Hanzi</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Niveau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oui</td>\n",
       "      <td>是的</td>\n",
       "      <td>shì de</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non</td>\n",
       "      <td>不是</td>\n",
       "      <td>bù (shì)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S'il-vous-plaît</td>\n",
       "      <td>请</td>\n",
       "      <td>qĭng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merci</td>\n",
       "      <td>谢谢</td>\n",
       "      <td>xièxie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je vous en prie</td>\n",
       "      <td>没关系</td>\n",
       "      <td>méiguānxì</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Qu'est-ce-qu'il fait chaud aujourd'hui!</td>\n",
       "      <td>今天真热呀！</td>\n",
       "      <td>Jīntiān zhēn rè ya!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Il y aura du brouillard demain</td>\n",
       "      <td>明天会有雾</td>\n",
       "      <td>Míngtiān huì yǒu wù</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Au voleur !</td>\n",
       "      <td>抓小偷！</td>\n",
       "      <td>Zhuā xiǎotōu!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>On m'a volé</td>\n",
       "      <td>我被抢劫了</td>\n",
       "      <td>Wǒ bèi qiǎngjiéle</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Ta connexion est mauvaise</td>\n",
       "      <td>你的网络不好</td>\n",
       "      <td>Nǐ de wǎngluò bù hǎo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      French   Hanzi                Pinyin  \\\n",
       "0                                        Oui      是的                shì de   \n",
       "1                                        Non      不是              bù (shì)   \n",
       "2                            S'il-vous-plaît       请                  qĭng   \n",
       "3                                      Merci      谢谢                xièxie   \n",
       "4                            Je vous en prie     没关系             méiguānxì   \n",
       "..                                       ...     ...                   ...   \n",
       "995  Qu'est-ce-qu'il fait chaud aujourd'hui!  今天真热呀！   Jīntiān zhēn rè ya!   \n",
       "996           Il y aura du brouillard demain   明天会有雾   Míngtiān huì yǒu wù   \n",
       "997                              Au voleur !    抓小偷！         Zhuā xiǎotōu!   \n",
       "998                              On m'a volé   我被抢劫了     Wǒ bèi qiǎngjiéle   \n",
       "999                Ta connexion est mauvaise  你的网络不好  Nǐ de wǎngluò bù hǎo   \n",
       "\n",
       "     Niveau  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "995       4  \n",
       "996       5  \n",
       "997       5  \n",
       "998       6  \n",
       "999       5  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜 cài  :  plat (aliments)\n"
     ]
    }
   ],
   "source": [
    "def vocflash2(motchinois):\n",
    "    index = data[data[\"Hanzi\"] == motchinois].index\n",
    "    id = index[0]\n",
    "    print(data[\"Hanzi\"][id],data[\"Pinyin\"][id], \" : \", data[\"FR\"][id])\n",
    "    \n",
    "vocflash2(\"菜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影  : \n",
      "film\n",
      "crayon; CL: 支[zhi1], 枝[zhi1], 杆[gan3]\n",
      "couleur; CL: 个\n",
      "maison\n"
     ]
    }
   ],
   "source": [
    "def voc121(motchinois, niveau):\n",
    "    \n",
    "    mot_nlp = nlpCh(motchinois)\n",
    "    index = data[data[\"Hanzi\"] == motchinois].index\n",
    "    id = index[0]\n",
    "    \n",
    "    voc = data[data[\"Niveau\"] <= niveau]\n",
    "    \n",
    "    for i in voc[\"Hanzi\"]:\n",
    "        test = nlpCh(i)\n",
    "        if test[0].pos_ != mot_nlp[0].pos_ or test.text == motchinois:\n",
    "            voc = voc.drop(voc[voc[\"Hanzi\"] == i].index)\n",
    "    \n",
    "    voc = voc.reset_index()\n",
    "    x1, x2, x3 = random.sample(range(1, len(voc)), 3)\n",
    "\n",
    "    print(motchinois, \" : \")\n",
    "    print(data[\"FR\"][id])\n",
    "    print(voc[\"FR\"][x1])\n",
    "    print(voc[\"FR\"][x2])\n",
    "    print(voc[\"FR\"][x3])\n",
    "\n",
    "voc121(\"电影\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影  : \n",
      "film\n",
      "plat (aliments)\n",
      "se reposer; au repos\n",
      "taxi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French</th>\n",
       "      <th>Hanzi</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Niveau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>On se retrouve devant le cinéma</td>\n",
       "      <td>我们在电影院前见面</td>\n",
       "      <td>Wǒmen zài diànyǐngyuàn qián jiànmiàn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Tu as déjà vu ce film?</td>\n",
       "      <td>你看过了这部电影</td>\n",
       "      <td>Nǐ kànguòle zhè bù diànyǐng</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ça sort la semaine prochaine</td>\n",
       "      <td>它（电影）下周上映</td>\n",
       "      <td>Tā (diànyǐng) xià zhōu shàngyìng</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              French      Hanzi  \\\n",
       "498  On se retrouve devant le cinéma  我们在电影院前见面   \n",
       "502           Tu as déjà vu ce film?   你看过了这部电影   \n",
       "504     ça sort la semaine prochaine  它（电影）下周上映   \n",
       "\n",
       "                                   Pinyin  Niveau  \n",
       "498  Wǒmen zài diànyǐngyuàn qián jiànmiàn       3  \n",
       "502           Nǐ kànguòle zhè bù diànyǐng       3  \n",
       "504      Tā (diànyǐng) xià zhōu shàngyìng       2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#afficher également les phrases qui contiennent le mot en paramètre\n",
    "def voc18(motchinois, niveau):\n",
    "    voc121(motchinois, niveau)\n",
    "    \n",
    "    display(data_phrase[data_phrase['Hanzi'].str.contains(motchinois, na=False, regex=False)])\n",
    "        \n",
    "voc18(\"电影\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat  : \n",
      "猫 māo\n",
      "岁 suì\n",
      "老师 lǎo shī\n",
      "医生 yī shēng\n"
     ]
    }
   ],
   "source": [
    "def voc122(motfr, niveau):\n",
    "    \n",
    "    mot_nlp = nlpFr(motfr)\n",
    "    index = data[data[\"FR\"] == motfr].index\n",
    "    id = index[0]\n",
    "    \n",
    "    voc = data[data[\"Niveau\"] <= niveau]\n",
    "    \n",
    "    for i in voc[\"FR\"]:\n",
    "        test = nlpFr(i)\n",
    "        if test[0].pos_ != mot_nlp[0].pos_ or test.text == motfr:\n",
    "            voc = voc.drop(voc[voc[\"FR\"] == i].index)\n",
    "    \n",
    "    voc = voc.reset_index()\n",
    "    x1, x2, x3 = random.sample(range(1, len(voc)), 3)\n",
    "\n",
    "    print(motfr, \" : \")\n",
    "    print(data[\"Hanzi\"][id], data[\"Pinyin\"][id])\n",
    "    print(voc[\"Hanzi\"][x1], voc[\"Pinyin\"][x1])\n",
    "    print(voc[\"Hanzi\"][x2], voc[\"Pinyin\"][x2])\n",
    "    print(voc[\"Hanzi\"][x3], voc[\"Pinyin\"][x3])\n",
    "\n",
    "voc122(\"chat\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chien', '狗', '马', '猫', '动物')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#utilisation de la similarité\n",
    "\n",
    "def voc16(motfr, niveau):\n",
    "    \n",
    "    index = data[data[\"FR\"] == motfr].index\n",
    "    id = index[0]\n",
    "    \n",
    "    mot_nlp = nlpCh(data[\"Hanzi\"][id])\n",
    "\n",
    "    distractor = []\n",
    "    voc = data[data[\"Niveau\"] <= niveau]\n",
    "    \n",
    "    x1, x2, x3 = 0, 0, 0\n",
    "    distractor2 = \"\"\n",
    "    distractor3 = \"\"\n",
    "        \n",
    "        \n",
    "    for i in voc[\"Hanzi\"]:\n",
    "        i_nlp = nlpCh(i)\n",
    "        \n",
    "        if mot_nlp.similarity(i_nlp) > x1 and mot_nlp.similarity(i_nlp) != 1:\n",
    "            x1 = mot_nlp.similarity(i_nlp)\n",
    "            distractor1 = i_nlp.text\n",
    "\n",
    "            if x1 > x2:\n",
    "                x = x2\n",
    "                x2 = x1\n",
    "                x1 = x\n",
    "\n",
    "                pivot = distractor2\n",
    "                distractor2 = distractor1\n",
    "                distractor1 = pivot\n",
    "\n",
    "                if x2 > x3:\n",
    "                    x = x3\n",
    "                    x3 = x2\n",
    "                    x2 = x\n",
    "                    pivot = distractor3\n",
    "                    distractor3 = distractor2\n",
    "                    distractor2 = pivot\n",
    "            \n",
    "            \n",
    "                        \n",
    "    return(motfr, mot_nlp.text, distractor1, distractor2, distractor3)\n",
    "    \n",
    "voc16(\"chien\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices - phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qu'est-ce-qu'il fait chaud aujourd'hui! 今天真热呀！\n",
      "Qu'est-ce-qu'il fait chaud aujourd'hui!  :  ...真热呀！\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ici un trou est fait de façon aléatoire\n",
    "\n",
    "def closeTest1(phrase):\n",
    "    \n",
    "    index = data_phrase[data_phrase[\"French\"] == phrase].index\n",
    "    id = index[0]\n",
    "    \n",
    "    phrasechi = nlpCh(data_phrase[\"Hanzi\"][id])\n",
    "    \n",
    "    trou = random.randint(0, len(phrasechi) - 3)\n",
    "    print(phrase, data_phrase[\"Hanzi\"][id])\n",
    "    phrase_a_trou = re.sub(phrasechi[trou].text, \"...\", phrasechi.text)\n",
    "        \n",
    "    print(phrase, \" : \", phrase_a_trou)\n",
    "    \n",
    "closeTest1(\"Qu'est-ce-qu'il fait chaud aujourd'hui!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code en erreur, mais repris differement dans la génération, en utilisant les exos de similarité precedemment généré,\n",
    "#ce qui a permis de gagner bcp de temps sur la génération\n",
    "\n",
    "import re\n",
    "\n",
    "def closeTest2(phrase):\n",
    "\n",
    "    index = data_phrase[data_phrase[\"French\"] == phrase].index\n",
    "    id = index[0]\n",
    "    \n",
    "    phrasefr = nlpFr(data_phrase[\"French\"][id])\n",
    "    phrasechi = nlpCh(data_phrase[\"Hanzi\"][id])\n",
    "    \n",
    "    trou = random.randint(0, len(phrasechi) - 3)\n",
    "    print(phrasechi.text, phrasechi[trou].text)\n",
    "    phrase_a_trou = re.sub(phrasechi[trou].text, \"...\", phrasechi.text)\n",
    "    \n",
    "    print(phrasefr.text, \" : \", phrase_a_trou)\n",
    "    \n",
    "    index = data[data[\"Hanzi\"] == phrasechi[trou].text].index\n",
    "    id2 = index[0]\n",
    "    print(id2)\n",
    "    \n",
    "    distractor = []\n",
    "    #print(distractor)\n",
    "    for t in data[\"Hanzi\"]:\n",
    "        mot = data[\"Hanzi\"][0]\n",
    "        if nlpCh(t)[0].pos_ == nlpCh(mot)[0].pos_: \n",
    "            distractor.append(t)  \n",
    "    \n",
    "    dist1, sim1, dist2, sim2, dist3, sim3 = voc16(distractor, 2)\n",
    "    print(\"\\n\",dist1, \" : \", sim1, \"\\n\", dist2, \" : \", sim2, \"\\n\", dist3, \" : \", sim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Traduire avec l'aide des mots proposés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"明天会有雾\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separe les mots et mélange leur ordre\n",
    "def phrase1(phrase):\n",
    "    distractor = []\n",
    "    answer = []\n",
    "    while distractor == answer:\n",
    "        for i in phrase:\n",
    "            answer.append(i)\n",
    "            distractor.append(i)\n",
    "        random.shuffle(distractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# marquer les frontière entre les mots\n",
    "transformer les conjug / genre / question / temps / distracteur quantificateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mélange une phras + ajout de distracteur erreur fréquente\n",
    "#prise en compte des erreurs récurrentes\n",
    "#是 + ADJ Verb\n",
    "#是 au lieu de 在\n",
    "\n",
    "def phrase1(phrase):\n",
    "    \n",
    "    index = data_phrase[data_phrase[\"Hanzi\"] == phrase].index\n",
    "    id = index[0]\n",
    "    phrase_fr = data_phrase[\"French\"][id]\n",
    "    phrase_nlp = nlpCh(phrase)\n",
    "    distractor = []\n",
    "    for i in phrase_nlp:\n",
    "        # pos : adv and dep : advmod => verbadj and indicator of the degree\n",
    "        if i.pos_ == \"ADV\" and i.dep_ == \"advmod\":\n",
    "            print(\"indicateur de degré : \", i)\n",
    "            distractor.append(\"是\")\n",
    "            \n",
    "            \n",
    "        #erreur commune : shi au lieu de hen ou shi + hen\n",
    "        \n",
    "        if i.text == \"在\": #pos du compl de lieux et sa dep, peut être mieux\n",
    "            print(\"lieux : \", i)\n",
    "            distractor.append(\"是\")\n",
    "            \n",
    "        distractor.append(i)\n",
    "    random.shuffle(distractor)\n",
    "    print(phrase_fr)\n",
    "    print(distractor)\n",
    "    \n",
    "phrase1(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimentation exercice de négation\n",
    "\n",
    "def negative(phrase):\n",
    "    \n",
    "    index = data_phrase[data_phrase[\"Hanzi\"] == phrase].index\n",
    "    id = index[0]\n",
    "    \n",
    "    phrasefr = nlpCh(data_phrase[\"French\"][id])\n",
    "        \n",
    "    print(phrasefr)\n",
    "    print(phrase)\n",
    "    \n",
    "negative(\"你想吃点什么吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc18():\n",
    "    \n",
    "    negation_phrase = data_phrase[data_phrase['Hanzi'].str.contains(\"没\" and \"不\", na=False, regex=False)]\n",
    "        \n",
    "voc18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Homophone\" et \"Homonyme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_phonetique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhōngguó\n",
      "['n', 'z', 'zh', 'g', 'h', 'ō', 'ó', 'ōng', 'u', 'uó']\n"
     ]
    }
   ],
   "source": [
    "word = \"Zhōngguó\"\n",
    "print(word)\n",
    "def distractor_pinyin(word):\n",
    "    \n",
    "    morpho_distractor = []\n",
    "\n",
    "    for t in data_phonetique[\"Pinyin_consonne\"]:\n",
    "        if type(t) == float:\n",
    "            break\n",
    "        elif t in word.lower():\n",
    "            morpho_distractor.append(t)\n",
    "\n",
    "    for h in data_phonetique[\"Pinyin_voyelle\"]:\n",
    "        if type(h) == float:\n",
    "            break\n",
    "        elif h in word.lower():\n",
    "            morpho_distractor.append(h)\n",
    "    print(morpho_distractor)\n",
    "    \n",
    "distractor_pinyin(\"Zhōngguó\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreurs fréquentes\n",
    "\n",
    "1- Shi avec un adj_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mark:clf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"zh\" id=\"eb899c6df2e44f59866b1dff5c7eff93-0\" class=\"displacy\" width=\"575\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">一</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">条</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">衣服。</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eb899c6df2e44f59866b1dff5c7eff93-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eb899c6df2e44f59866b1dff5c7eff93-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eb899c6df2e44f59866b1dff5c7eff93-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eb899c6df2e44f59866b1dff5c7eff93-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark:clf</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'VERB',\n",
       " 'PUNCT',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'NOUN',\n",
       " 'PART',\n",
       " 'PART',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlpCh(\"一条衣服。\")\n",
    "#doc = nlpCh(\"你是法国人\")\n",
    "\n",
    "print(doc[1].dep_)\n",
    "displacy.render(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
